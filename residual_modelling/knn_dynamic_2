import numpy as np
import pickle
from mlagents_envs.environment import UnityEnvironment
from mlagents_envs.base_env import ActionTuple
from sklearn.neighbors import KNeighborsRegressor
import matplotlib.pyplot as plt

# --- CONFIGURATION ---
env_prior_path = "envs/real_dynamic/prior_env/prior.x86_64"
env_real_path = "envs/real_dynamic/real_env/real.x86_64"

n_steps = 80  # Number of steps per episode
k = 5  # Number of neighbors in KNN
change_action = 20  # Change action every X steps
data_x = []  # Features: [sim_vel (6D) + sim_acc (6D) + action (6D)]
data_y = []  # Target: Force rescaling (6D)
n = 0

while n < 3:
    prev_sim_vel = np.zeros(6)
    prev_real_vel = np.zeros(6)

    # --- INITIALIZE ENVIRONMENTS ---
    env_sim = UnityEnvironment(file_name=env_prior_path, seed=1, worker_id=0, side_channels=[])
    print("Loaded prior env!")
    env_real = UnityEnvironment(file_name=env_real_path, seed=1, worker_id=1, side_channels=[])
    print("Loaded real env!")

    env_sim.reset()
    env_real.reset()

    # Retrieve behavior
    behavior_name_sim = list(env_sim.behavior_specs.keys())[0]
    behavior_spec_sim = env_sim.behavior_specs[behavior_name_sim]
    num_agents = len(env_sim.get_steps(behavior_name_sim)[0])
    action_size = behavior_spec_sim.action_spec.continuous_size  # Expecting 6DOF forces

    behavior_name_real = list(env_real.behavior_specs.keys())[0]
    behavior_spec_real = env_real.behavior_specs[behavior_name_real]

    print(f"\nStarting simulation {n} for data collection...")

    # Initialize actions (change every `change_action` steps)
    actions = np.random.uniform(-1, 1, (num_agents, action_size)).astype(np.float32)

    for step in range(n_steps):
        # --- OBSERVE STATES FIRST ---
        env_sim.step()
        env_real.step()

        sim_steps, _ = env_sim.get_steps(behavior_name_sim)
        real_steps, _ = env_real.get_steps(behavior_name_real)

        for agent_id in sim_steps.agent_id:
            # Extract velocity data
            sim_vel_u = sim_steps[agent_id].obs[0][6:12]
            real_vel_u = real_steps[agent_id].obs[0][6:12]

            # Convert velocities to NED frame
            sim_vel = np.array([sim_vel_u[2], sim_vel_u[0], -sim_vel_u[1],   
                                sim_vel_u[5], sim_vel_u[3], -sim_vel_u[4]])

            real_vel = np.array([real_vel_u[2], real_vel_u[0], -real_vel_u[1],
                                 real_vel_u[5], real_vel_u[3], -real_vel_u[4]])

            # Compute real and simulated accelerations
            real_acc = (real_vel - prev_real_vel)
            sim_acc = (sim_vel - prev_sim_vel)

            # Compute force rescale factor
            force_rescale = real_acc / (sim_acc + 1e-10)  # Avoid division by zero

            # Store data (skip first step)
            if step > 0:
                data_x.append(np.concatenate([sim_vel, sim_acc, actions[agent_id]]))
                data_y.append(force_rescale)

            # --- APPLY NEW ACTIONS AFTER STATE OBSERVATION ---
            if step % change_action == 0:
                actions = np.random.uniform(-1, 1, (num_agents, action_size)).astype(np.float32)
                print(f"Step {step}: Updated Actions:\n{actions}")

            # Send actions to the environments
            action_tuple = ActionTuple(continuous=actions)
            env_sim.set_actions(behavior_name_sim, action_tuple)
            env_real.set_actions(behavior_name_real, action_tuple)

            # Update previous velocities for next step
            prev_real_vel = real_vel
            prev_sim_vel = sim_vel

    env_sim.close()
    env_real.close()
    n += 1

# Save full dataset
knn_x = np.array(data_x)
knn_y = np.array(data_y)
with open("residual_data_6dof_train.pkl", "wb") as f:
    pickle.dump((knn_x, knn_y), f)

print("\nTraining data collection complete! Full dataset saved.")
num_actions = 6 
plt.figure(figsize=(12, 6))
for i in range(num_actions):
    plt.scatter(knn_x[:, -num_actions + i], knn_y[:, i], alpha=0.5, label=f"Action {i+1}")

plt.xlabel("Action Input")
plt.ylabel("Force Scaling Factor")
plt.title("Force Scaling Factor vs. Action Input")
plt.legend()
plt.grid()
plt.show()

# --- TRAINING KNN ---
knn = KNeighborsRegressor(n_neighbors=k, weights='distance', algorithm='auto', leaf_size=30)
knn.fit(knn_x, knn_y)

# --- TESTING KNN ---
print("\nTESTING KNN.")
env_sim = UnityEnvironment(file_name=env_prior_path, seed=1, worker_id=0, side_channels=[])
env_real = UnityEnvironment(file_name=env_real_path, seed=1, worker_id=1, side_channels=[])
env_sim.reset()
env_real.reset()

prev_sim_vel = np.zeros(6)
prev_real_vel = np.zeros(6)
data_test = []

actions = np.random.uniform(-1, 1, (num_agents, action_size)).astype(np.float32)
for step in range(n_steps):
    # Step environments
    env_sim.step()
    env_real.step()

    sim_steps, _ = env_sim.get_steps(behavior_name_sim)
    real_steps, _ = env_real.get_steps(behavior_name_real)

    for agent_id in sim_steps.agent_id:
        sim_vel_u = sim_steps[agent_id].obs[0][6:12]
        real_vel_u = real_steps[agent_id].obs[0][6:12]

        sim_vel = np.array([sim_vel_u[2], sim_vel_u[0], -sim_vel_u[1],   
                            sim_vel_u[5], sim_vel_u[3], -sim_vel_u[4]])
        
        real_vel = np.array([real_vel_u[2], real_vel_u[0], -real_vel_u[1],
                             real_vel_u[5], real_vel_u[3], -real_vel_u[4]])

        real_acc = (real_vel - prev_real_vel)
        sim_acc = (sim_vel - prev_sim_vel)

        if step > 0:
            data_test.append(np.concatenate([sim_vel, sim_acc, actions[agent_id]]))

        prev_real_vel = real_vel
        prev_sim_vel = sim_vel

    if step % change_action == 0:
        actions = np.random.uniform(-1, 1, (num_agents, action_size)).astype(np.float32)

    knn_test = np.array(data_test)
    predicted_scaling = knn.predict(knn_test)
    corrected_action = actions * predicted_scaling

    action_tuple_knn = ActionTuple(continuous=corrected_action)
    env_sim.set_actions(behavior_name_sim, action_tuple_knn)
    env_real.set_actions(behavior_name_real, action_tuple)

env_sim.close()
env_real.close()

print("Testing KNN complete!")
